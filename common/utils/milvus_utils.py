from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from sentence_transformers import SentenceTransformer
import re
import os


def milvus_text_embedding_pipeline(
    milvus_host: str = "127.0.0.1",
    milvus_port: str = "19530",
    collection_name: str = "sample_text_embeddings",
    model_name: str = "Qwen/Qwen3-Embedding-0.6B",
    text_file_path: str = "../data/sample_text.txt",
    max_length: int = 2048,
    batch_size: int = 16
):
    """
    Functional pipeline up to insertion (Steps 1‚Äì7):
        1. Connect to Milvus
        2. Load embedding model
        3. Load text file
        4. Generate embeddings
        5. Create Milvus collection
        6. Insert data
        7. Create index

    Returns
    -------
    model : SentenceTransformer
        Loaded embedding model (for reuse)
    collection : Collection
        Milvus collection object
    """

    # ---------------------------------------------------
    # 1Ô∏è‚É£ Connect to Milvus
    # ---------------------------------------------------
    connections.connect("default", host=milvus_host, port=milvus_port)
    print(f"‚úÖ Connected to Milvus at {milvus_host}:{milvus_port}")

    # ---------------------------------------------------
    # 2Ô∏è‚É£ Load Embedding Model
    # ---------------------------------------------------
    model = SentenceTransformer(model_name)
    print(f"‚úÖ Loaded embedding model: {model_name}")

    # ---------------------------------------------------
    # 3Ô∏è‚É£ Read text file
    # ---------------------------------------------------
    if not os.path.exists(text_file_path):
        raise FileNotFoundError(f"‚ùå Text file not found: {text_file_path}")

    with open(text_file_path, "r", encoding="utf-8") as f:
        text = " ".join(f.readlines())
        docs = [line[:max_length] for line in re.split(r'\n\s*\n', text.strip()) if len(line.strip()) > 50]
    print(f"üìÑ Loaded {len(docs)} text segments from {text_file_path}")

    # ---------------------------------------------------
    # 4Ô∏è‚É£ Generate embeddings
    # ---------------------------------------------------
    embeddings = model.encode(docs, batch_size=batch_size, show_progress_bar=True)
    print(f"‚úÖ Generated embeddings with shape: {embeddings.shape}")

    # ---------------------------------------------------
    # 5Ô∏è‚É£ Define or recreate collection
    # ---------------------------------------------------
    if utility.has_collection(collection_name):
        print(f"‚ö†Ô∏è Collection '{collection_name}' exists. Dropping it...")
        utility.drop_collection(collection_name)
        print(f"üóëÔ∏è Collection '{collection_name}' dropped.")

    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embeddings.shape[1]),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=max_length * 3),
    ]

    schema = CollectionSchema(fields, description="Text embeddings using Qwen3 model")
    collection = Collection(name=collection_name, schema=schema)
    print(f"‚úÖ Created Milvus collection: {collection_name}")

    # ---------------------------------------------------
    # 6Ô∏è‚É£ Insert embeddings + text
    # ---------------------------------------------------
    collection.insert([embeddings.tolist(), docs])
    collection.flush()
    print(f"‚úÖ Inserted {len(docs)} records into '{collection_name}'")

    # ---------------------------------------------------
    # 7Ô∏è‚É£ Create index
    # ---------------------------------------------------
    index_params = {
        "metric_type": "IP",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 1024}
    }
    collection.create_index("embedding", index_params)
    print("‚úÖ Index created on 'embedding'")

    return model, collection



# ---------------------------------------------------
# üîç 8Ô∏è‚É£ 9Ô∏è‚É£ 10Ô∏è‚É£ ‚Äî Search & Display as separate function
# ---------------------------------------------------
def milvus_search_query(
    model: SentenceTransformer,
    collection: Collection,
    query_text: str,
    top_k: int = 5
):
    """
    Handles search and results display (Steps 8‚Äì10):
        8. Load collection into memory
        9. Perform vector search
        10. Display top results
    """

    # ---------------------------------------------------
    # 8Ô∏è‚É£ Load collection
    # ---------------------------------------------------
    collection.load()
    print("‚úÖ Collection loaded into memory")

    print(f"üìä Total entities in collection: {collection.num_entities}")

    # ---------------------------------------------------
    # 9Ô∏è‚É£ Perform vector search
    # ---------------------------------------------------
    query_embedding = model.encode(query_text)
    search_params = {"metric_type": "IP", "params": {"nprobe": 8}}

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text"],
    )

    # ---------------------------------------------------
    # üîü Display results
    # ---------------------------------------------------
    print(f"\nüîç Top {top_k} results for query: '{query_text}'")
    for hits in results:
        for hit in hits:
            print(f"‚û° text: {hit.entity.get('text')}")
            print(f"   similarity: {hit.distance:.4f}")
            print("-" * 60)
